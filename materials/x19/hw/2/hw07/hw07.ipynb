{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name:\n",
    "\n",
    "Section:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7: Testing Hypotheses\n",
    "Please complete this notebook by filling in the cells provided. Before you begin, execute the following cell to load the provided tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gofer-grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it. \n",
    "\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "# These lines load the tests.\n",
    "\n",
    "from gofer.ok import check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recommended Reading**: \n",
    "* [Testing Hypotheses](https://inferentialthinking.com/chapters/11/Testing_Hypotheses.html)\n",
    "1) For all problems that you must write explanations and sentences for, you **must** provide your answer in the designated space.  This can include: \n",
    "    A) Sentence reponses to questions that ask for an explanation \n",
    "    B) Numeric responses to multiple choice questions\n",
    "    C) Programming code\n",
    "    \n",
    "2) Moreover, throughout this homework and all future ones, please be sure to not re-assign variables throughout the notebook! For example, if you use `max_temperature` in your answer to one question, do not reassign it later on. Otherwise, you will fail tests that you thought you were passing previously!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you're finished, select \"Save and Checkpoint\" in the File menu. Your name and course section number should be in the first and last cell of the assignment. Be sure you have run all cells with code and that the output from that is showing. Then click \"Print Preview\" in the File menu. Print a copy from there in pdf format. (This means you right click and choose print and choose \"save as pdf\" from your printer options.) You will need to submit the pdf in Canvas by the deadline.\n",
    "\n",
    "The gopher grader output and/or output from your coding are essential to helping your instructor grade your work correctly and in a timely manner.\n",
    "\n",
    "Files submitted that are missing the required output will lose some to all points so double check your pdf before submitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Catching Cheaters\n",
    "Suppose you are a casino owner, and your casino runs a very simple game of chance.  The dealer flips a coin.  The customer wins $\\$$9 from the casino if it's heads and loses $\\$$10 if it's tails.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1** <br /> Assuming no one is cheating and the coin is fair, if a customer plays twice, what is the chance they make money?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "manual_grade": true,
    "manual_problem_id": "catching_cheaters_1"
   },
   "outputs": [],
   "source": [
    "p_winning_after_two_flips = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "check('tests/q1_1.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A certain customer plays the game 20 times and wins 13 of the bets.  You suspect that the customer is cheating!  That is, you think that their chance of winning is higher than the normal chance of winning.\n",
    "\n",
    "You decide to test your hunch using the outcomes of the 20 games you observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2** <br /> Define the null hypothesis and alternative hypothesis for this investigation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "for_assignment_type": "student",
    "manual_grade": true,
    "manual_problem_id": "catching_cheaters_2"
   },
   "source": [
    "**Null hypothesis:** ...\n",
    "\n",
    "**Alternative hypothesis:** ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3** <br /> Given the outcome of 20 games, which of the following test statistics would be a reasonable choice for this hypothesis test? \n",
    "\n",
    "*Hint*: For a refresher on choosing test statistics, check out this section on [Test Statistics](https://inferentialthinking.com/chapters/11/3/Decisions_and_Uncertainty.html).\n",
    "\n",
    "1. Whether there is at least one win.\n",
    "1. Whether there is at least one loss.\n",
    "1. The number of wins.\n",
    "1. The number of wins minus the number of losses.\n",
    "1. The total variation distance between the probability distribution of a fair coin and the observed distribution of heads and tails.\n",
    "1. The total amount of money that the customer won.\n",
    "\n",
    "Assign `reasonable_test_statistics` to a **list** of numbers corresponding to these test statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": false
   },
   "outputs": [],
   "source": [
    "reasonable_test_statistics = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "check('tests/q1_3.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you decide to use the number of wins as your test statistic.\n",
    "\n",
    "**Question 1.4** <br /> Write a function called `simulate` that generates exactly one simulation of your test statistic under the Null Hypothesis.  It should take no arguments.  It should return the number of wins in 20 games simulated under the assumption that the result of each game is sampled from a fair coin that lands heads or lands tails with a 50% chance.\n",
    "\n",
    "*Hint*: You may find the textbook [section](https://www.inferentialthinking.com/chapters/11/1/Assessing_Models#predicting-the-statistic-under-the-model) on the `sample_proportions` function to be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false
   },
   "outputs": [],
   "source": [
    "check('tests/q1_4.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5** <br /> Using 10,000 trials, generate simulated values of the number of wins in 20 games. Assign `test_statistics_under_null` to an array that stores the result of each of these trials.\n",
    "\n",
    "*Hint*: Feel free to use the function you defined in Question 1.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "test_statistics_under_null = ...\n",
    "repetitions = ...\n",
    "\n",
    "...\n",
    "\n",
    "test_statistics_under_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false
   },
   "outputs": [],
   "source": [
    "check('tests/q1_5.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.6** <br /> Using the results from Question 1.5, generate a histogram of the empirical distribution of the number of wins in 20 games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "for_assignment_type": "student",
    "manual_grade": true,
    "manual_problem_id": "catching_cheaters_6"
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.7** <br /> Compute an empirical P-value for this test.\n",
    "\n",
    "*Hint:* Which values of our test statistic are in the direction of the alternative hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false
   },
   "outputs": [],
   "source": [
    "p_value = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "check('tests/q1_7.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.8** <br /> Suppose you use a P-value cutoff of 1%. What do you conclude from the hypothesis test? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_grade": true,
    "manual_problem_id": "catching_cheaters_8"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.9** <br /> Is `p_value` the probability that the customer cheated, or the probability that the customer didn't cheat, or neither? If neither, what is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_grade": true,
    "manual_problem_id": "catching_cheaters_9"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.10** <br /> Is 1% (the P-value cutoff) the probability that the customer cheated, or the probability that the customer didn't cheat, or neither? If neither, what is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_grade": true,
    "manual_problem_id": "catching_cheaters_10"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.11** <br /> Suppose you run this test for 400 different customers after observing each customer play 20 games.  When you reject the null hypothesis for a customer, you accuse that customer of cheating.  If no customers were actually cheating, can we compute how many customers we will incorrectly accuse of cheating? If so, what is the number? Explain your answer. Assume a 1% P-value cutoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_grade": true,
    "manual_problem_id": "catching_cheaters_10"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Landing a Spacecraft\n",
    "(Note: This problem describes something that's close to [a real story with a very exciting video](http://www.space.com/29119-spacex-reusable-rocket-landing-crash-video.html), but the details have been changed somewhat.)\n",
    "\n",
    "SpaceY, a company that builds and tests spacecraft, is testing a new reusable launch system.  Most spacecrafts use a \"first stage\" rocket that propels a smaller payload craft away from Earth, then falls back to the ground and crashes.  SpaceY's new system is designed to land safely at a landing pad at a certain location, ready for later reuse.  If it doesn't land in the right location, it crashes, and the very, very expensive vehicle is destroyed.\n",
    "\n",
    "SpaceY has tested this system over 1000 times.  Ordinarily, the vehicle doesn't land exactly on the landing pad.  For example, a gust of wind might move it by a few meters just before it lands.  It's reasonable to think of these small errors as random.  That is, the landing locations are drawn from some distribution over locations on the surface of Earth, centered around the landing pad.\n",
    "\n",
    "Run the next cell to see a plot of those locations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinary_landing_spots = Table.read_table(\"ordinary_landing_spots.csv\")\n",
    "ordinary_landing_spots.scatter(\"x\", label=\"Landing locations\")\n",
    "plt.scatter(0, 0, c=\"w\", s=1000, marker=\"*\", label=\"Landing pad\")\n",
    "plt.legend(scatterpoints=1, bbox_to_anchor=(1.6, .5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During one test, the vehicle lands far away from the landing pad and crashes.  SpaceY investigators suspect there was a problem unique to this landing, a problem that wasn't part of the ordinary pattern of variation in landing locations.  They think a software error in the guidance system caused the craft to incorrectly attempt to land at a spot other than the landing pad.  The guidance system engineers think there was nothing out of the ordinary in this landing, and that there was no special problem with the guidance system.\n",
    "\n",
    "Run the cell below to see a plot of the 1100 ordinary landings and the crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "landing_spot = make_array(80.59, 30.91)\n",
    "ordinary_landing_spots.scatter(\"x\", label=\"Other landings\")\n",
    "plt.scatter(0, 0, c=\"w\", s=1000, marker=\"*\", label=\"Landing pad\")\n",
    "plt.scatter(landing_spot.item(0), landing_spot.item(1), marker=\"*\", c=\"r\", s=1000, label=\"Crash site\")\n",
    "plt.legend(scatterpoints=1, bbox_to_anchor=(1.6, .5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1** <br /> Suppose we'd like to use hypothesis testing to shed light on this question.  We've written down an alternative hypothesis below.  What is a reasonable null hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "for_assignment_type": "student",
    "manual_grade": true,
    "manual_problem_id": "landing_1"
   },
   "source": [
    "**Null hypothesis:** ...\n",
    "\n",
    "**Alternative hypothesis:** This landing was special; its location was a draw from some other distribution, not the distribution from which the other 1100 landing locations were drawn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2** <br /> What's a good test statistic for this hypothesis test? \n",
    "\n",
    "*Hint:* A test statistic can be almost anything, but a *good* test statistic varies informatively depending on whether the null is true. So for this example, we might think about a test statistic that would be small if the null is true, and large otherwise. If we want to compare landings, we might want to see *how far* each landing is from some *reference point*, so we can compare all landings from the same vantage point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "for_assignment_type": "student",
    "manual_grade": true,
    "manual_problem_id": "landing_2"
   },
   "source": [
    "**Test statistic:** ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3** <br /> Write a function called `landing_test_statistic`.  It should take two arguments: an \"x\" location and a \"y\" location (both numbers).  It should return the value of your test statistic for a landing at those coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "manual_grade": true,
    "manual_problem_id": "landing_3"
   },
   "outputs": [],
   "source": [
    "def landing_test_statistic(x_coordinate, y_coordinate):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4** <br /> The next three cells compute a P-value using your test statistic. Describe the test procedure in words. Is there a simulation involved? If so, what is being simulated? If not, why not? Where are we getting the data from? What kind of calculations are being performed? How are we calculating our P-value? \n",
    "\n",
    "*Hint:* Think about what a [simulation](https://inferentialthinking.com/chapters/09/3/Simulation.html) actually consists of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_test_stat = landing_test_statistic(\n",
    "    landing_spot.item(0),\n",
    "    landing_spot.item(1))\n",
    "\n",
    "observed_test_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_stats = make_array()\n",
    "repetitions = ordinary_landing_spots.num_rows\n",
    "\n",
    "for i in np.arange(repetitions):\n",
    "    null_stat = landing_test_statistic(\n",
    "        ordinary_landing_spots.column('x').item(i),\n",
    "        ordinary_landing_spots.column('y').item(i))\n",
    "    null_stats = np.append(null_stats, null_stat)\n",
    "    \n",
    "null_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = np.count_nonzero(null_stats >= observed_test_stat) / len(null_stats)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "for_assignment_type": "student",
    "manual_problem_id": "landing_4"
   },
   "source": [
    "*Write your answer here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing Dice\n",
    "Students in a Data Science class want to figure out whether a six-sided die is fair or not. On a fair die, each face of the die appears with chance 1/6 on each roll, regardless of the results of other rolls.  Otherwise, a die is called unfair.  We can describe a die by the probability of landing on each face.  This table describes an example of a die that is unfairly weighted toward 1:\n",
    "\n",
    "|Face|Probability|\n",
    "|-|-|\n",
    "|1|.5|\n",
    "|2|.1|\n",
    "|3|.1|\n",
    "|4|.1|\n",
    "|5|.1|\n",
    "|6|.1|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1** <br /> Define a null hypothesis and an alternative hypothesis to test whether a six-sided die is fair or not. \n",
    "\n",
    "*Hint:* Remember that an unfair die is one for which each face does not have an equal chance of appearing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "for_assignment_type": "student",
    "manual_grade": true,
    "manual_problem_id": "testing_dice_1"
   },
   "source": [
    "**Null hypothesis:** ...\n",
    "\n",
    "**Alternative hypothesis:** ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to test the die by rolling it 5 times. The proportions of the 6 faces in these 5 rolls are stored in a table with 6 rows.  For example, here is the table we'd make if the die rolls ended up being 1, 2, 3, 3, and 5:\n",
    "\n",
    "|Face|Proportion|\n",
    "|-|-|\n",
    "|1|.2|\n",
    "|2|.2|\n",
    "|3|.4|\n",
    "|4|.0|\n",
    "|5|.2|\n",
    "|6|.0|\n",
    "\n",
    "The function `mystery_test_statistic`, defined below, takes a single table like this as its argument and returns a number (which we will use as a test statistic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: We've intentionally used unhelpful function and\n",
    "# variable names to avoid giving away answers.  It's rarely\n",
    "# a good idea to use names like \"x\" in your code.\n",
    "\n",
    "def mystery_test_statistic(sample):\n",
    "    x = np.ones(1) * (1/6)\n",
    "    y = (sample.column('Proportion') - x)\n",
    "    return np.mean(y**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2** <br /> Describe in words what the test statistic is.  Is it equivalent to the total variation distance between the observed face distribution and the fair die distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_grade": true,
    "manual_problem_id": "testing_dice_2"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `simulate_observations_and_test` takes as its argument a table describing the probability distribution of a die.  It simulates one set of 5 rolls of that die, then tests the null hypothesis about that die using our test statistic function above.  It returns `False` if it *rejects* the null hypothesis about the die, and `True` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The probability distribution table for a fair die:\n",
    "fair_die = Table().with_columns(\n",
    "        \"Face\", np.arange(1, 6+1),\n",
    "        \"Probability\", [1/6, 1/6, 1/6, 1/6, 1/6, 1/6])\n",
    "\n",
    "def simulate_observations_and_test(actual_die):\n",
    "    \"\"\"Simulates die rolls from actual_die and tests the hypothesis that the die is fair.\n",
    "    \n",
    "    Returns False if that hypothesis is rejected, and True otherwise.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sample_size = 5\n",
    "    p_value_cutoff = .2\n",
    "    num_simulations = 250\n",
    "    \n",
    "    # Compute the observed value of the test statistic.\n",
    "    observation_set = sample_proportions(sample_size, actual_die.column(\"Probability\"))\n",
    "    observation_props_table = Table().with_columns('Face', actual_die.column('Face'), 'Proportion', observation_set)\n",
    "    observed_statistic = mystery_test_statistic(observation_props_table)\n",
    "    \n",
    "    # Simulate the test statistic repeatedly to get an \n",
    "    # approximation to the probability distribution of \n",
    "    # the test statistic, as predicted by the model in \n",
    "    # the null hypothesis. Store the simulated values \n",
    "    # of the test statistic in an array.\n",
    "    simulated_statistics = make_array()\n",
    "    for _ in np.arange(num_simulations):\n",
    "        one_observation_set_under_null = sample_proportions(sample_size, fair_die.column(\"Probability\"))\n",
    "        simulated_props_table = Table().with_columns('Face', fair_die.column('Face'), 'Proportion', one_observation_set_under_null)\n",
    "        simulated_statistic = mystery_test_statistic(simulated_props_table)\n",
    "        simulated_statistics = np.append(simulated_statistics, simulated_statistic)\n",
    "        \n",
    "    # Compute the P-value\n",
    "    p_value = np.count_nonzero(simulated_statistics >= observed_statistic) / num_simulations\n",
    "    \n",
    "    # If the P-value is below the cutoff, reject the \n",
    "    # null hypothesis and return False. Otherwise, \n",
    "    # return True.\n",
    "    return p_value >= p_value_cutoff\n",
    "\n",
    "# Calling the function to simulate a test of a fair die:\n",
    "simulate_observations_and_test(fair_die)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3** <br /> Use your knowledge of hypothesis tests and interpretation of the code above to compute the probability that `simulate_observations_and_test` returns `False` when its argument is `fair_die` (which is defined above the function). In other words, what are the odds that we reject the Null Hypothesis if the die is actually fair?\n",
    "\n",
    "You can call the function a few times to see what it does, but **don't** perform a simulation to compute this probability.  Use your knowledge of hypothesis tests. You shouldn't have to write any code to answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": false
   },
   "outputs": [],
   "source": [
    "probability_of_false = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "check('tests/q3_3.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4** <br /> Why is your answer to Question 3.3 the correct probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_grade": true,
    "manual_problem_id": "testing_dice_4"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5** <br /> Simulate the process of running `simulation_observations_and_test` 300 times. Assign `test_results` to an array that stores the result of each of these trials.\n",
    "\n",
    "**Note:** This will be a little slow. 300 repetitions of the simulation should require a minute or so of computation, and it should suffice to get an answer that's roughly correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "num_test_simulations = 300\n",
    "test_results = ...\n",
    "\n",
    "...\n",
    "\n",
    "# Don't change the following line.\n",
    "test_results.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check('tests/q3_5.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6** <br /> Verify your answer to Question 3.3 by computing an approximate probability that `simulation_observations_and_test` returns `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "approximate_probability_of_false = ...\n",
    "approximate_probability_of_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "check('tests/q3_6.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.7** <br /> From the perspective of someone who wants to know the truth about the die, is it good or bad for the function to return `False` when its argument is `fair_die`? Why is it good or bad?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_grade": true,
    "manual_problem_id": "testing_dice_7"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. A Potpourri of Tests\n",
    "The rest of this homework is optional. Do it for your own practice, but it will not be incorporated into the final grading!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1 (Optional)** <br /> Many scientific disciplines use 5% as a standard cutoff for rejecting the null hypothesis when conducting hypothesis tests.  Suppose for the sake of argument that every scientific paper hinges on exactly one hypothesis test with a 5% cutoff.  After learning about hypothesis testing, Thomas despairs about the state of scientific research, wondering:\n",
    "\n",
    "> \"Doesn't this mean that 5% of all scientific papers are wrong?\"\n",
    "\n",
    "Under what conditions would Thomas’s worry be realistic, and why is it not entirely accurate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_problem_id": "potpourri_1"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_problem_id": "potpourri_2"
   },
   "source": [
    "**Question 4.2 (Optional)** <br /> Many scientists hope to make exciting and unintuitive discoveries.  Often, the null hypothesis in an hypothesis test is something boring (\"the sky is blue\"), while the alternative is surprising (\"the sky is not blue!\").\n",
    "\n",
    "Suppose a scientist has an exciting but incorrect idea, so that their null hypothesis is *truly correct*.  When an hypothesis test is run on a sample of data, it fails to reject the null when using a 5% cutoff.  Disappointed but determined, the scientist gathers 10 more samples and runs the same test on each sample (running 10 separate hypothesis tests, each with a 5% cutoff).  If any of the tests rejects the null, the scientist publishes that one.  What is the chance that any of those tests rejects the null hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The scientist in this scenario is acting very unethically, but (probably milder) forms of this [*publication bias*](https://en.wikipedia.org/wiki/Publication_bias) seem to be a real problem in science today. See a relevant [xkcd](https://xkcd.com/882/) below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![So, uh, we did the green study again and got no link. It was probably a--' 'RESEARCH CONFLICTED ON GREEN JELLY BEAN/ACNE LINK; MORE STUDY RECOMMENDED!](https://imgs.xkcd.com/comics/significant.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Submission\n",
    "Once you're finished, select \"Save and Checkpoint\" in the File menu. Your name and course section number should be in the first and last cell of the assignment. Be sure you have run all cells with code and that the output from that is showing. \n",
    "\n",
    "#### Double check that you have completed all of the free response questions as the autograder does NOT check that and YOU are responsible for knowing those questions are there and completing them as part of the grade for this homework.\n",
    "\n",
    "When ready, click \"Print Preview\" in the File menu. Print a copy from there in pdf format. (This means you right click and choose print and choose \"save as pdf\" from your printer options.) You will need to submit the pdf in Canvas by the deadline.\n",
    "\n",
    "The gopher grader output and/or output from your coding are essential to helping your instructor grade your work correctly and in a timely manner.\n",
    "\n",
    "Files submitted that are missing the required output will lose some to all points so double check your pdf before submitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "import glob\n",
    "from gofer.ok import grade_notebook\n",
    "if not globals().get('__GOFER_GRADER__', False):\n",
    "    display(grade_notebook('hw07.ipynb', sorted(glob.glob('tests/q*.py'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name:\n",
    "\n",
    "Section:"
   ]
  }
 ],
 "metadata": {
  "assignment": "hw07",
  "course": "SJCC",
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "section": "2"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}